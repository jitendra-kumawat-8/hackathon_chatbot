{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from flask import Flask, render_template, url_for, request\n",
    "app=Flask(__name__)\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 patterns\n",
      "28 tags: ['Biopsy', 'Breast Cancer', 'Breast ultrasound', 'Chemotherapy', 'Diagnosis', 'Diagnostic mammograms', 'Doctors for Breast Cancer Treatment', 'Hormonal Therapy', 'Hormone Therapy', 'MRI', 'Mammography and MRI', 'Memmography hurt', 'Prevention', 'Radiation Therapy', 'Screening age for breast Cancer Diagnosis', 'Screening of breast cancer', 'Side Effects of Breast Cancer Therapy', 'Side Effects of each therapy', 'Surgery', 'Symptoms', 'Treatments for breast cancer', 'inspect: change in colour of the breast', 'inspect: changes to the skin', 'inspect: discharge from nipples', 'inspect: swelling of breast', 'inspect: symmetry of breast and nipple', 'lump on palpating', 'retraction of nipple']\n",
      "109 unique stemmed words: [\"'s\", 'At', 'Do', 'I', 'Is', 'a', 'about', 'affect', 'age', 'and', 'are', 'be', 'begin', 'between', 'biopsi', 'breast', 'by', 'call', 'can', 'cancer', 'carri', 'caus', 'chang', 'chemotherapi', 'colour', 'diagnos', 'diagnosi', 'differ', 'discharg', 'do', 'doctor', 'doe', 'due', 'each', 'effect', 'elabor', 'explain', 'factor', 'find', 'for', 'from', 'have', 'hormon', 'how', 'hurt', 'i', 'if', 'in', 'inspect', 'is', 'it', 'long-term', 'lump', 'mammogram', 'mammographi', 'me', 'mean', 'measur', 'more', 'mri', 'my', 'nippl', 'of', 'on', 'out', 'palpat', 'perform', 'physic', 'pleas', 'possibl', 'prevent', 'process', 'radiat', 'reduc', 'replac', 'retract', 'risk', 'safe', 'screen', 'see', 'should', 'side', 'skin', 'some', 'step', 'suggest', 'surgeri', 'swell', 'symmetri', 'symptom', 'taken', 'tell', 'that', 'the', 'therapi', 'think', 'to', 'treat', 'treatment', 'type', 'ultrasound', 'undergo', 'we', 'well-establish', 'what', 'when', 'which', 'work', 'you']\n",
      "109 28\n",
      "Epoch [100/800], Loss: 0.2008\n",
      "Epoch [200/800], Loss: 0.0170\n",
      "Epoch [300/800], Loss: 0.0080\n",
      "Epoch [400/800], Loss: 0.0043\n",
      "Epoch [500/800], Loss: 0.0011\n",
      "Epoch [600/800], Loss: 0.0001\n",
      "Epoch [700/800], Loss: 0.0002\n",
      "Epoch [800/800], Loss: 0.0002\n",
      "final loss: 0.0002\n",
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word) for word in tokenized_sentence]\n",
    "    # initialize bag with 0 for each word\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words: \n",
    "            bag[idx] = 1\n",
    "\n",
    "    return bag\n",
    "\n",
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    # add to tag list\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        all_words.extend(w)\n",
    "        # add to xy pair\n",
    "        xy.append((w, tag))\n",
    "\n",
    "# stem and lower each word\n",
    "ignore_words = ['?', '.', '!',':']\n",
    "all_words = [stemmer.stem(w) for w in all_words if w not in ignore_words]\n",
    "# remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "\n",
    "print(len(xy), \"patterns\")\n",
    "print(len(tags), \"tags:\", tags)\n",
    "print(len(all_words), \"unique stemmed words:\", all_words)\n",
    "\n",
    "# create training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 800\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')\n",
    "\n",
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=109, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=28, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('intents.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [05/Oct/2020 00:30:45] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2020 00:30:45] \"GET /static/style.css HTTP/1.1\" 404 -\n",
      "[2020-10-05 00:30:52,230] ERROR in app: Exception on /get [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-27-ba8a266e55c0>\", line 31, in get_bot_response\n",
      "    botText = predict(userText)\n",
      "  File \"<ipython-input-27-ba8a266e55c0>\", line 14, in predict\n",
      "    if(userText.lower() in [\"hi\",\"hello\",\"hellow\",\"waddup\",\"how are you\",\"whatsup\",\"hey there\"]):\n",
      "AttributeError: 'list' object has no attribute 'lower'\n",
      "127.0.0.1 - - [05/Oct/2020 00:30:52] \"GET /get?msg=breast%20cancer HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [05/Oct/2020 00:31:09] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Oct/2020 00:31:09] \"GET /static/style.css HTTP/1.1\" 404 -\n",
      "[2020-10-05 00:31:14,093] ERROR in app: Exception on /get [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Da Awesomeness\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-27-ba8a266e55c0>\", line 31, in get_bot_response\n",
      "    botText = predict(userText)\n",
      "  File \"<ipython-input-27-ba8a266e55c0>\", line 14, in predict\n",
      "    if(userText.lower() in [\"hi\",\"hello\",\"hellow\",\"waddup\",\"how are you\",\"whatsup\",\"hey there\"]):\n",
      "AttributeError: 'list' object has no attribute 'lower'\n",
      "127.0.0.1 - - [05/Oct/2020 00:31:14] \"GET /get?msg=breast%20cancer HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "def predict(userText):\n",
    "    userText = nltk.word_tokenize(userText)\n",
    "    X = bag_of_words(userText, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                botText = random.choice(intent['responses'])\n",
    "    else:\n",
    "        botText = \"Please be more clear\"\n",
    "    return(botText)\n",
    "    \n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/get\")\n",
    "def get_bot_response():\n",
    "    userText = request.args.get(\"msg\")\n",
    "    botText = predict(userText)\n",
    "    return(botText)\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
